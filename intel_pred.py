# -*- coding: utf-8 -*-
"""intel_pred.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NGnGPN83zt98CG7zCnmR4kXEucN_LAx_
"""

from keras.models import Sequential
import keras as k
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Conv2D, Activation, BatchNormalization, GlobalAvgPool2D, MaxPool2D, Flatten, Dense

from keras import preprocessing

from google.colab import drive
drive.mount("/content/gdrive")

import zipfile
from google.colab import drive

drive.mount('/content/drive/')

zip_ref = zipfile.ZipFile("/content/archive.zip", 'r')
zip_ref.extractall()
zip_ref.close()

file1 = ('/content/seg_train/seg_train')

file = ('/content/seg_test/seg_test')

from keras.preprocessing.image import ImageDataGenerator

train_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1./255, horizontal_flip=True)

train_gen = train_datagen.flow_from_directory(directory = file, subset='training', target_size=(384,384), shuffle=True, class_mode='categorical', batch_size=16)
test_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1./255)
test_gen = test_datagen.flow_from_directory(directory= file1, subset='validation', shuffle=True, class_mode='categorical', target_size=(384,384), batch_size=16)

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(6, activation='relu'))
model.add(tf.keras.layers.Conv2D(64, kernel_size=[2,2], padding='valid', activation='relu', input_shape=[384, 384, 3]))
model.add(tf.keras.layers.MaxPooling2D(pool_size=[2,2], strides=1, padding='valid'))
model.add(tf.keras.layers.Dense(6, activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=[2,2], strides=1, padding='valid'))
model.add(tf.keras.layers.Conv2D(32, kernel_size=[2,2],padding='valid', activation='relu' ))
model.add(tf.keras.layers.MaxPooling2D(pool_size=[2,2], strides=1, padding='valid'))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(6, activation='sigmoid'))
model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])

history= model.fit(train_gen, validation_data = test_gen, epochs=30, verbose=2)

model.save('intel_pred.h5')

train_loss, train_acc = model.evaluate(train_gen)
print("final train accuracy = {:.2f} , train loss = {:.2f}".format(train_acc*100, train_loss*100))



import cv2

import matplotlib.pyplot as plt

import numpy as np


x = plt.imread('/content/sea.jpg')
plt.imshow(x)

x = x/255

x = np.resize(x,(1,384,384,3))

x.shape

classes = list(train_gen.class_indices)

print(classes[np.argmax(model.predict(x))])









